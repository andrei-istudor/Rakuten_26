{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d0cc40",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b17a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from scipy.sparse import hstack\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081e3b6",
   "metadata": {},
   "source": [
    "# Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a193b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Größen in cm → umrechnen in inches\n",
    "cm = 1/2.54\n",
    "\n",
    "\n",
    "\n",
    "# marker und dicken von linien und der achsen und alles sollte einheitlich sein\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (18*cm, 8*cm),   # default: 18×8 cm\n",
    "    \"font.size\": 10,                    # Standardschriftgröße\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"figure.dpi\": 300, # für saubere Notebooks/Export\n",
    "    \"lines.linewidth\": 1.0,\n",
    "    \"lines.markersize\": 4,\n",
    "    \"axes.linewidth\": 1.0,\n",
    "    \"xtick.major.width\": 1.0,\n",
    "    \"ytick.major.width\": 1.0,\n",
    "    \"xtick.minor.width\": 1.0,\n",
    "    \"ytick.minor.width\": 1.0,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd921f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Project paths\n",
    "# -----------------------------\n",
    "\n",
    "EXPERIMENTS_DIR = Path(\"experiments/LinSVM\")\n",
    "EXPERIMENTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METRICS_PATH = EXPERIMENTS_DIR / \"metrics_long.csv\"   # long format: (experiment_id x class)\n",
    "RUNS_PATH    = EXPERIMENTS_DIR / \"runs_global.csv\"    # one row per experiment run\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset column config\n",
    "# -----------------------------\n",
    "TEXT_VARIANT_COL  = \"text_stripped\"   # from your current notebook\n",
    "LABEL_COL = \"prdtypecode\"\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eee329df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_empty_csv(path, columns):\n",
    "    if path.exists():\n",
    "        return pd.read_csv(path)\n",
    "    return pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "def append_and_dedup(df_old, df_new, subset):\n",
    "    out = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    out = out.drop_duplicates(subset=subset, keep=\"last\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def save_confusion_matrices(experiment_id, cm_raw, cm_norm):\n",
    "    out_dir = EXPERIMENTS_DIR / experiment_id\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(out_dir / \"confusion_raw.npy\", cm_raw)\n",
    "    np.save(out_dir / \"confusion_norm.npy\", cm_norm)\n",
    "\n",
    "\n",
    "def log_run_global(experiment_id, cfg, global_metrics):\n",
    "    cols = [\"experiment_id\", \"config_json\", \"accuracy\", \"macro_f1\", \"weighted_f1\"]\n",
    "    df_old = load_or_empty_csv(RUNS_PATH, cols)\n",
    "\n",
    "    row = {\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"config_json\": json.dumps(cfg, sort_keys=True),\n",
    "        **global_metrics,\n",
    "    }\n",
    "    df_new = pd.DataFrame([row], columns=cols)\n",
    "    df_out = append_and_dedup(df_old, df_new, subset=[\"experiment_id\"])\n",
    "    df_out.to_csv(RUNS_PATH, index=False)\n",
    "\n",
    "def log_metrics_long(experiment_id, cfg, report_dict, train_counts):\n",
    "    # Minimal per-class columns that are always meaningful\n",
    "    base_cols = [\n",
    "        \"experiment_id\", \"class_id\",\n",
    "        \"precision\", \"recall\", \"f1\", \"support_val\",\n",
    "        \"n_train_class\",\n",
    "        \"config_json\",\n",
    "    ]\n",
    "\n",
    "    # Optional \"nice-to-have\" columns (only filled if present)\n",
    "    optional_cols = [\n",
    "        \"vectorizer\",\n",
    "        \"model\",\n",
    "        \"class_weight\",\n",
    "        \"analyzer\", \"ngram_min\", \"ngram_max\", \"max_features\",   # single-vectorizer case\n",
    "        \"word_ngram_min\", \"word_ngram_max\", \"word_max_features\", \"word_min_df\",\n",
    "        \"char_ngram_min\", \"char_ngram_max\", \"char_max_features\", \"char_min_df\",\n",
    "    ]\n",
    "\n",
    "    cols = base_cols + optional_cols\n",
    "\n",
    "    df_old = load_or_empty_csv(METRICS_PATH, cols)\n",
    "\n",
    "    rows = []\n",
    "    cfg_json = json.dumps(cfg, sort_keys=True)\n",
    "\n",
    "    for k, v in report_dict.items():\n",
    "        if k in (\"accuracy\", \"macro avg\", \"weighted avg\"):\n",
    "            continue\n",
    "\n",
    "        class_id = int(k)\n",
    "\n",
    "        row = {\n",
    "            \"experiment_id\": experiment_id,\n",
    "            \"class_id\": class_id,\n",
    "            \"precision\": float(v[\"precision\"]),\n",
    "            \"recall\": float(v[\"recall\"]),\n",
    "            \"f1\": float(v[\"f1-score\"]),\n",
    "            \"support_val\": int(v[\"support\"]),\n",
    "            \"n_train_class\": int(train_counts.get(class_id, 0)),\n",
    "            \"config_json\": cfg_json,\n",
    "        }\n",
    "\n",
    "        # Fill optional keys if they exist; otherwise leave blank/NaN\n",
    "        for key in optional_cols:\n",
    "            if key in cfg:\n",
    "                row[key] = cfg[key]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df_new = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    # If old file has fewer columns (from earlier runs), align columns before concat\n",
    "    for c in df_old.columns:\n",
    "        if c not in df_new.columns:\n",
    "            df_new[c] = np.nan\n",
    "    for c in df_new.columns:\n",
    "        if c not in df_old.columns:\n",
    "            df_old[c] = np.nan\n",
    "\n",
    "    df_new = df_new[df_old.columns]  # same order\n",
    "    df_out = append_and_dedup(df_old, df_new, subset=[\"experiment_id\", \"class_id\"])\n",
    "    df_out.to_csv(METRICS_PATH, index=False)\n",
    "\n",
    "\n",
    "def stratified_subsample(df, label_col, sample_size, random_state=42):\n",
    "    \"\"\"\n",
    "    Stratified subsampling that preserves class proportions.\n",
    "    sample_size = 0 or >= len(df)  -> full dataset\n",
    "    \"\"\"\n",
    "    if sample_size == 0 or sample_size >= len(df):\n",
    "        return df.copy().reset_index(drop=True)\n",
    "\n",
    "    frac = sample_size / len(df)\n",
    "\n",
    "    df_sub = (\n",
    "        df\n",
    "        .groupby(label_col, group_keys=False)\n",
    "        .apply(lambda x: x.sample(\n",
    "            n=max(1, int(len(x) * frac)),\n",
    "            random_state=random_state\n",
    "        ))\n",
    "        .sample(frac=1, random_state=random_state)  # shuffle\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# single vectorizer\n",
    "\n",
    "CFG = {\n",
    "    # data\n",
    "    \"run_name\": \"TF-IDF Word ngram (1,2)\",\n",
    "    \"experiment_id\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),  # unique run id\n",
    "    \"text_column\": TEXT_VARIANT_COL,\n",
    "    \"label_column\": LABEL_COL,\n",
    "    # vectorizer\n",
    "    \"analyzer\": \"word\",          # \"word\" or \"char\"\n",
    "    \"ngram_min\": 1,\n",
    "    \"ngram_max\": 2,\n",
    "    \"max_features\": 100000,\n",
    "\n",
    "    # model\n",
    "    \"model\": \"LinearSVC\",\n",
    "    \"class_weight\": \"balanced\",  # None or \"balanced\"\n",
    "    \"C\": 2\n",
    "}\n",
    "\n",
    "\n",
    "BASE_CFG = deepcopy(CFG)\n",
    "\n",
    "# max_features experiments\n",
    "EXPERIMENTS = [\n",
    "    {\"run_name\": \"TF-IDF Word ngram max_feat_run_1\",\n",
    "     \"max_features\": 20000,\n",
    "     }\n",
    "    ,\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_2\",\n",
    "        \"max_features\": 30000,\n",
    "        }\n",
    "    ,\n",
    "    {\"run_name\": \"TF-IDF Word ngram max_feat_run_3\",\n",
    "        \"max_features\": 50000,\n",
    "        }\n",
    "    ,\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_4\",\n",
    "        \"max_features\": 80000,\n",
    "        },\n",
    "    {\"run_name\": \"TF-IDF Word ngram max_feat_run_5\",\n",
    "        \"max_features\": 120000,\n",
    "        },\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_6\",\n",
    "        \"max_features\": 150000,\n",
    "        },\n",
    "    {\"run_name\": \"TF-IDF Word ngram max_feat_run_7\",\n",
    "        \"max_features\": 200000,\n",
    "        },\n",
    "    # -----------------------------\n",
    "    # same for char\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_1\",\n",
    "     \"ngram_min\":3,\n",
    "     \"ngram_max\":5,\n",
    "     \"analyzer\":\"char\",\n",
    "     \"max_features\": 20000,\n",
    "     },\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_2\",\n",
    "        \"ngram_min\":3,\n",
    "        \"ngram_max\":5,\n",
    "        \"analyzer\":\"char\",\n",
    "        \"max_features\": 50000,\n",
    "        },\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_3\",\n",
    "        \"ngram_min\":3,\n",
    "        \"ngram_max\":5,\n",
    "        \"analyzer\":\"char\",\n",
    "        \"max_features\": 80000,\n",
    "        },\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_4\",\n",
    "        \"ngram_min\":3,\n",
    "        \"ngram_max\":5,\n",
    "        \"analyzer\":\"char\",\n",
    "        \"max_features\": 120000,\n",
    "        },\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_5\",\n",
    "        \"ngram_min\":3,\n",
    "        \"ngram_max\":5,\n",
    "        \"analyzer\":\"char\",\n",
    "        \"max_features\": 150000,\n",
    "        },\n",
    "    {\"run_name\": \"TF-IDF Char ngram max_feat_run_6\",\n",
    "        \"ngram_min\":3,\n",
    "        \"ngram_max\":5,\n",
    "        \"analyzer\":\"char\",\n",
    "        \"max_features\": 200000\n",
    "        }\n",
    "]\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    {\"run_name\": f\"TF-IDF Word ngram max_feat_{nmin}_{nmax}\",\n",
    "     \"analyzer\": \"word\",\n",
    "     \"ngram_min\": nmin,\n",
    "     \"ngram_max\": nmax,\n",
    "     \"max_features\": 100000,\n",
    "     }\n",
    "    for nmin, nmax in [(1, 2), (1,3), (2,3), (2,4), (3,5)]\n",
    "] + [\n",
    "    {\"run_name\": f\"TF-IDF Char ngram max_feat_{nmin}_{nmax}\",\n",
    "     \"analyzer\": \"char\",\n",
    "     \"ngram_min\": nmin,\n",
    "     \"ngram_max\": nmax,\n",
    "     \"max_features\": 300000,\n",
    "     }\n",
    "    for nmin, nmax in [(2,3),(2,4),(3, 5),(3,4),(4,6)]\n",
    "]\n",
    "\n",
    "def make_cfg(base, overrides):\n",
    "    cfg = deepcopy(base)\n",
    "    cfg.update(overrides)\n",
    "    cfg[\"experiment_id\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348af2b0",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b21bef",
   "metadata": {},
   "source": [
    "# Single vectorizer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bed0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(cfg):\n",
    "    \"\"\"Run one experiment with given config.\"\"\"\n",
    "    # splitting is already done\n",
    "    # print config\n",
    "    \n",
    "    print(\"Running experiment with config:\")\n",
    "    print(json.dumps(cfg, indent=4))\n",
    "    \n",
    "    # train df\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    DATA_PATH_train = DATA_DIR / \"train.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(DATA_PATH_train)\n",
    "    # val df\n",
    "    DATA_PATH_val = DATA_DIR / \"test.csv\"\n",
    "    val_df = pd.read_csv(DATA_PATH_val)\n",
    "\n",
    "    #### LabelEncoder ###\n",
    "    ##############################################\n",
    "\n",
    "    # print shapes\n",
    "    print(f\"Train shape: {train_df.shape}\")\n",
    "    print(f\"Validation shape: {val_df.shape}\")\n",
    "\n",
    "    X_train = train_df[TEXT_VARIANT_COL].astype(str)\n",
    "    y_train = train_df[LABEL_COL].astype(str)\n",
    "\n",
    "        # validation data\n",
    "    X_val = val_df[TEXT_VARIANT_COL].astype(str)\n",
    "    y_val = val_df[LABEL_COL].astype(str)\n",
    "    \n",
    "    print(\"Experiment ID:\", CFG[\"experiment_id\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # Vectorizer\n",
    "    # -----------------------------\n",
    "    tfidf = TfidfVectorizer(\n",
    "        analyzer=CFG[\"analyzer\"],\n",
    "        ngram_range=(CFG[\"ngram_min\"], CFG[\"ngram_max\"]),\n",
    "        max_features=CFG[\"max_features\"],\n",
    "    )\n",
    "\n",
    "    X_train_vec = tfidf.fit_transform(X_train)\n",
    "    X_val_vec   = tfidf.transform(X_val)\n",
    "\n",
    "    print(\"Vectorized shapes:\")\n",
    "    print(\"X_train_vec:\", X_train_vec.shape)\n",
    "    print(\"X_val_vec  :\", X_val_vec.shape)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Model\n",
    "    # -----------------------------\n",
    "    clf = LinearSVC(\n",
    "        class_weight=CFG[\"class_weight\"],\n",
    "        C=CFG[\"C\"],\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    print(\"Model trained.\")\n",
    "\n",
    "    import joblib\n",
    "    \n",
    "    # save model, vectorizer, everything to reload without retraining\n",
    "    \n",
    "    out_dir = EXPERIMENTS_DIR / CFG[\"experiment_id\"]\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(clf, out_dir / \"model.joblib\")\n",
    "    joblib.dump(tfidf, out_dir / \"vectorizer.joblib\")\n",
    "    joblib.dump(CFG, out_dir / \"config.joblib\")\n",
    "    print(\"Model and vectorizer saved.\")\n",
    "    \n",
    "    # save X_val_vec and y_val for evaluation later\n",
    "    joblib.dump(X_val_vec, out_dir / \"X_val_vec.joblib\")\n",
    "    joblib.dump(y_val, out_dir / \"y_val.joblib\")\n",
    "    print(\"Validation data saved.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93166daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Word ngram max_feat_1_2\",\n",
      "    \"experiment_id\": \"20260120_230922\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"word\",\n",
      "    \"ngram_min\": 1,\n",
      "    \"ngram_max\": 2,\n",
      "    \"max_features\": 100000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_230922\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 100000)\n",
      "X_val_vec  : (16701, 100000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Word ngram max_feat_1_3\",\n",
      "    \"experiment_id\": \"20260120_231004\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"word\",\n",
      "    \"ngram_min\": 1,\n",
      "    \"ngram_max\": 3,\n",
      "    \"max_features\": 100000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_231004\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 100000)\n",
      "X_val_vec  : (16701, 100000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Word ngram max_feat_2_3\",\n",
      "    \"experiment_id\": \"20260120_231106\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"word\",\n",
      "    \"ngram_min\": 2,\n",
      "    \"ngram_max\": 3,\n",
      "    \"max_features\": 100000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_231106\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 100000)\n",
      "X_val_vec  : (16701, 100000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Word ngram max_feat_2_4\",\n",
      "    \"experiment_id\": \"20260120_231210\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"word\",\n",
      "    \"ngram_min\": 2,\n",
      "    \"ngram_max\": 4,\n",
      "    \"max_features\": 100000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_231210\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 100000)\n",
      "X_val_vec  : (16701, 100000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Word ngram max_feat_3_5\",\n",
      "    \"experiment_id\": \"20260120_231337\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"word\",\n",
      "    \"ngram_min\": 3,\n",
      "    \"ngram_max\": 5,\n",
      "    \"max_features\": 100000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_231337\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 100000)\n",
      "X_val_vec  : (16701, 100000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Char ngram max_feat_2_3\",\n",
      "    \"experiment_id\": \"20260120_231508\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"char\",\n",
      "    \"ngram_min\": 2,\n",
      "    \"ngram_max\": 3,\n",
      "    \"max_features\": 300000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_231508\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 67383)\n",
      "X_val_vec  : (16701, 67383)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Char ngram max_feat_2_4\",\n",
      "    \"experiment_id\": \"20260120_231635\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"char\",\n",
      "    \"ngram_min\": 2,\n",
      "    \"ngram_max\": 4,\n",
      "    \"max_features\": 300000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_231635\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 300000)\n",
      "X_val_vec  : (16701, 300000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Char ngram max_feat_3_5\",\n",
      "    \"experiment_id\": \"20260120_231907\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"char\",\n",
      "    \"ngram_min\": 3,\n",
      "    \"ngram_max\": 5,\n",
      "    \"max_features\": 300000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_231907\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 300000)\n",
      "X_val_vec  : (16701, 300000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Char ngram max_feat_3_4\",\n",
      "    \"experiment_id\": \"20260120_232221\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"char\",\n",
      "    \"ngram_min\": 3,\n",
      "    \"ngram_max\": 4,\n",
      "    \"max_features\": 300000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_232221\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 300000)\n",
      "X_val_vec  : (16701, 300000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "Running experiment with config:\n",
      "{\n",
      "    \"run_name\": \"TF-IDF Char ngram max_feat_4_6\",\n",
      "    \"experiment_id\": \"20260120_232417\",\n",
      "    \"text_column\": \"text_stripped\",\n",
      "    \"label_column\": \"prdtypecode\",\n",
      "    \"analyzer\": \"char\",\n",
      "    \"ngram_min\": 4,\n",
      "    \"ngram_max\": 6,\n",
      "    \"max_features\": 300000,\n",
      "    \"model\": \"LinearSVC\",\n",
      "    \"class_weight\": \"balanced\",\n",
      "    \"C\": 2\n",
      "}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260120_232417\n",
      "Vectorized shapes:\n",
      "X_train_vec: (66800, 300000)\n",
      "X_val_vec  : (16701, 300000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n"
     ]
    }
   ],
   "source": [
    "for exp in EXPERIMENTS:\n",
    "    CFG = make_cfg(BASE_CFG, exp)\n",
    "    run_experiment(CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined word and char\n",
    "\n",
    "CFG = {\n",
    "    \"experiment_id\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),  # unique run id\n",
    "    \"text_column\": TEXT_VARIANT_COL,\n",
    "    \"label_column\": LABEL_COL,\n",
    "\n",
    "    # word tfidf\n",
    "    \"word_analyzer\": \"word\",\n",
    "    \"word_ngram_min\": 1,\n",
    "    \"word_ngram_max\": 2,\n",
    "    \"word_max_features\": 200000,\n",
    "    \"word_min_df\": 2,\n",
    "    \"word_sublinear_tf\": True,\n",
    "\n",
    "    # char tfidf\n",
    "    \"char_analyzer\": \"char\",\n",
    "    \"char_ngram_min\": 3,\n",
    "    \"char_ngram_max\": 5,\n",
    "    \"char_max_features\": 300000,\n",
    "    \"char_min_df\": 3,\n",
    "    \"char_sublinear_tf\": True,\n",
    "\n",
    "    # model\n",
    "    \"model\": \"LinearSVC\",\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"C\": 2\n",
    "}\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    {\"run_name\": f\"TF-IDF Word+Char ngram combined C={c}\",\n",
    "     \"C\": c}\n",
    "    for c in [0.01, 0.1, 1, 2, 5, 10, 20]\n",
    "]\n",
    "\n",
    "BASE_CFG = deepcopy(CFG)\n",
    "\n",
    "# update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41318f",
   "metadata": {},
   "source": [
    "# Two vectorizer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5bbbd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_2(cfg):\n",
    "    \"\"\"Run one experiment with given config.\"\"\"\n",
    "    # splitting is already done\n",
    "\n",
    "    # train df\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    DATA_PATH_train = DATA_DIR / \"train.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(DATA_PATH_train)\n",
    "    # val df\n",
    "    DATA_PATH_val = DATA_DIR / \"test.csv\"\n",
    "    val_df = pd.read_csv(DATA_PATH_val)\n",
    "\n",
    "    #### LabelEncoder ###\n",
    "    ##############################################\n",
    "\n",
    "    # print shapes\n",
    "    print(f\"Train shape: {train_df.shape}\")\n",
    "    print(f\"Validation shape: {val_df.shape}\")\n",
    "\n",
    "    X_train = train_df[TEXT_VARIANT_COL].astype(str)\n",
    "    y_train = train_df[LABEL_COL].astype(str)\n",
    "\n",
    "        # validation data\n",
    "    X_val = val_df[TEXT_VARIANT_COL].astype(str)\n",
    "    y_val = val_df[LABEL_COL].astype(str)\n",
    "    \n",
    "    print(\"Experiment ID:\", CFG[\"experiment_id\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # Vectorizers\n",
    "    # -----------------------------\n",
    "    tfidf_word = TfidfVectorizer(\n",
    "        analyzer=CFG[\"word_analyzer\"],\n",
    "        ngram_range=(CFG[\"word_ngram_min\"], CFG[\"word_ngram_max\"]),\n",
    "        max_features=CFG[\"word_max_features\"],\n",
    "        min_df=CFG[\"word_min_df\"],\n",
    "        sublinear_tf=CFG[\"word_sublinear_tf\"],\n",
    "    )\n",
    "\n",
    "    tfidf_char = TfidfVectorizer(\n",
    "        analyzer=CFG[\"char_analyzer\"],\n",
    "        ngram_range=(CFG[\"char_ngram_min\"], CFG[\"char_ngram_max\"]),\n",
    "        max_features=CFG[\"char_max_features\"],\n",
    "        min_df=CFG[\"char_min_df\"],\n",
    "        sublinear_tf=CFG[\"char_sublinear_tf\"],\n",
    "    )\n",
    "\n",
    "    # Fit/transform\n",
    "    X_train_word = tfidf_word.fit_transform(X_train)\n",
    "    X_val_word   = tfidf_word.transform(X_val)\n",
    "\n",
    "    X_train_char = tfidf_char.fit_transform(X_train)\n",
    "    X_val_char   = tfidf_char.transform(X_val)\n",
    "\n",
    "    # Stack features\n",
    "    X_train_vec = hstack([X_train_word, X_train_char]).tocsr()\n",
    "    X_val_vec   = hstack([X_val_word, X_val_char]).tocsr()\n",
    "\n",
    "    print(\"Stacked shapes:\")\n",
    "    print(\"X_train_vec:\", X_train_vec.shape)\n",
    "    print(\"X_val_vec  :\", X_val_vec.shape)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Model\n",
    "    # -----------------------------\n",
    "    clf = LinearSVC(\n",
    "        class_weight=CFG[\"class_weight\"],\n",
    "        random_state=RANDOM_STATE,\n",
    "        C=CFG[\"C\"],    \n",
    "    )\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    print(\"Model trained.\")\n",
    "\n",
    "    # save model, vectorizer, everything to reload without retraining\n",
    "    import joblib\n",
    "    \n",
    "     # save model, vectorizer, everything to reload without retraining\n",
    "    out_dir = EXPERIMENTS_DIR / CFG[\"experiment_id\"]\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(clf, out_dir / \"model.joblib\")\n",
    "    joblib.dump(tfidf_word, out_dir / \"vectorizer_word.joblib\")\n",
    "    joblib.dump(tfidf_char, out_dir / \"vectorizer_char.joblib\")\n",
    "    joblib.dump(CFG, out_dir / \"config.joblib\")\n",
    "    print(\"Model and vectorizer saved.\")\n",
    "    \n",
    "    # save X_val_vec and y_val for evaluation later\n",
    "    joblib.dump(X_val_vec, out_dir / \"X_val_vec.joblib\")\n",
    "    joblib.dump(y_val, out_dir / \"y_val.joblib\")\n",
    "    print(\"Validation data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d8968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_id': '20260121_093702', 'text_column': 'text_stripped', 'label_column': 'prdtypecode', 'word_analyzer': 'word', 'word_ngram_min': 1, 'word_ngram_max': 2, 'word_max_features': 200000, 'word_min_df': 2, 'word_sublinear_tf': True, 'char_analyzer': 'char', 'char_ngram_min': 3, 'char_ngram_max': 5, 'char_max_features': 300000, 'char_min_df': 3, 'char_sublinear_tf': True, 'model': 'LinearSVC', 'class_weight': 'balanced', 'C': 0.01, 'run_name': 'TF-IDF Word+Char ngram combined C=0.01'}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260121_093702\n",
      "Stacked shapes:\n",
      "X_train_vec: (66800, 500000)\n",
      "X_val_vec  : (16701, 500000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "{'experiment_id': '20260121_094047', 'text_column': 'text_stripped', 'label_column': 'prdtypecode', 'word_analyzer': 'word', 'word_ngram_min': 1, 'word_ngram_max': 2, 'word_max_features': 200000, 'word_min_df': 2, 'word_sublinear_tf': True, 'char_analyzer': 'char', 'char_ngram_min': 3, 'char_ngram_max': 5, 'char_max_features': 300000, 'char_min_df': 3, 'char_sublinear_tf': True, 'model': 'LinearSVC', 'class_weight': 'balanced', 'C': 0.1, 'run_name': 'TF-IDF Word+Char ngram combined C=0.1'}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260121_094047\n",
      "Stacked shapes:\n",
      "X_train_vec: (66800, 500000)\n",
      "X_val_vec  : (16701, 500000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "{'experiment_id': '20260121_094436', 'text_column': 'text_stripped', 'label_column': 'prdtypecode', 'word_analyzer': 'word', 'word_ngram_min': 1, 'word_ngram_max': 2, 'word_max_features': 200000, 'word_min_df': 2, 'word_sublinear_tf': True, 'char_analyzer': 'char', 'char_ngram_min': 3, 'char_ngram_max': 5, 'char_max_features': 300000, 'char_min_df': 3, 'char_sublinear_tf': True, 'model': 'LinearSVC', 'class_weight': 'balanced', 'C': 1, 'run_name': 'TF-IDF Word+Char ngram combined C=1'}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260121_094436\n",
      "Stacked shapes:\n",
      "X_train_vec: (66800, 500000)\n",
      "X_val_vec  : (16701, 500000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "{'experiment_id': '20260121_094909', 'text_column': 'text_stripped', 'label_column': 'prdtypecode', 'word_analyzer': 'word', 'word_ngram_min': 1, 'word_ngram_max': 2, 'word_max_features': 200000, 'word_min_df': 2, 'word_sublinear_tf': True, 'char_analyzer': 'char', 'char_ngram_min': 3, 'char_ngram_max': 5, 'char_max_features': 300000, 'char_min_df': 3, 'char_sublinear_tf': True, 'model': 'LinearSVC', 'class_weight': 'balanced', 'C': 2, 'run_name': 'TF-IDF Word+Char ngram combined C=2'}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260121_094909\n",
      "Stacked shapes:\n",
      "X_train_vec: (66800, 500000)\n",
      "X_val_vec  : (16701, 500000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "{'experiment_id': '20260121_095512', 'text_column': 'text_stripped', 'label_column': 'prdtypecode', 'word_analyzer': 'word', 'word_ngram_min': 1, 'word_ngram_max': 2, 'word_max_features': 200000, 'word_min_df': 2, 'word_sublinear_tf': True, 'char_analyzer': 'char', 'char_ngram_min': 3, 'char_ngram_max': 5, 'char_max_features': 300000, 'char_min_df': 3, 'char_sublinear_tf': True, 'model': 'LinearSVC', 'class_weight': 'balanced', 'C': 5, 'run_name': 'TF-IDF Word+Char ngram combined C=5'}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260121_095512\n",
      "Stacked shapes:\n",
      "X_train_vec: (66800, 500000)\n",
      "X_val_vec  : (16701, 500000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "{'experiment_id': '20260121_100209', 'text_column': 'text_stripped', 'label_column': 'prdtypecode', 'word_analyzer': 'word', 'word_ngram_min': 1, 'word_ngram_max': 2, 'word_max_features': 200000, 'word_min_df': 2, 'word_sublinear_tf': True, 'char_analyzer': 'char', 'char_ngram_min': 3, 'char_ngram_max': 5, 'char_max_features': 300000, 'char_min_df': 3, 'char_sublinear_tf': True, 'model': 'LinearSVC', 'class_weight': 'balanced', 'C': 10, 'run_name': 'TF-IDF Word+Char ngram combined C=10'}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260121_100209\n",
      "Stacked shapes:\n",
      "X_train_vec: (66800, 500000)\n",
      "X_val_vec  : (16701, 500000)\n",
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n",
      "{'experiment_id': '20260121_101030', 'text_column': 'text_stripped', 'label_column': 'prdtypecode', 'word_analyzer': 'word', 'word_ngram_min': 1, 'word_ngram_max': 2, 'word_max_features': 200000, 'word_min_df': 2, 'word_sublinear_tf': True, 'char_analyzer': 'char', 'char_ngram_min': 3, 'char_ngram_max': 5, 'char_max_features': 300000, 'char_min_df': 3, 'char_sublinear_tf': True, 'model': 'LinearSVC', 'class_weight': 'balanced', 'C': 20, 'run_name': 'TF-IDF Word+Char ngram combined C=20'}\n",
      "Train shape: (66800, 6)\n",
      "Validation shape: (16701, 6)\n",
      "Experiment ID: 20260121_101030\n",
      "Stacked shapes:\n",
      "X_train_vec: (66800, 500000)\n",
      "X_val_vec  : (16701, 500000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taoufiq\\OneDrive\\ML_Engineer\\rakuten_challenge\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n",
      "Model and vectorizer saved.\n",
      "Validation data saved.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for exp in EXPERIMENTS:\n",
    "    CFG = make_cfg(BASE_CFG, exp)\n",
    "    print(CFG)\n",
    "    run_experiment_2(CFG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
